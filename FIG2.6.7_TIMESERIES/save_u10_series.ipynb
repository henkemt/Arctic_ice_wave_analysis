{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00dc5f2b-7ef0-4e97-945c-8be61737b95d",
   "metadata": {},
   "source": [
    "# Preprocess U10 Series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d015e418-e66d-48fe-81e0-5e7e3f089520",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import geopandas as gpd\n",
    "import shapely.vectorized\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b290ef6-53ba-4e1a-a630-6b8bc616f613",
   "metadata": {},
   "source": [
    "### Function to find, read, and concatenate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc65e7c7-376e-48ca-9948-eb2c1ee2f555",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GCM FUNCTIONS\n",
    "def yearcheck(file, year,month):\n",
    "    check = False\n",
    "    with xr.open_dataset(file) as ds:\n",
    "        time = ds.coords['time'].values[:]\n",
    "        \n",
    "        if type(time[0]) == np.datetime64:\n",
    "            time = pd.to_datetime(time) \n",
    "            \n",
    "        ds_years= [time[i].year for i in range(len(time))]\n",
    "        \n",
    "        if year in ds_years:\n",
    "            check = True\n",
    "        \n",
    "        if check == True:\n",
    "            ds = ds.sel(time=ds.time.dt.year.isin([year]))\n",
    "            ds = ds.sel(time=ds.time.dt.month.isin([month]))\n",
    "            dt = np.array(ds.coords['time'][:])\n",
    "            if len(dt) == 0:\n",
    "                check = False\n",
    "    \n",
    "    return check\n",
    "\n",
    "def extract_gcm_data(ncfile,var,year,month):\n",
    "    with xr.open_dataset(ncfile) as ds:\n",
    "        ds = ds.sel(time=ds.time.dt.year.isin([year]))\n",
    "        ds = ds.sel(time=ds.time.dt.month.isin([month]))\n",
    "        dt = np.array(ds.coords['time'][:])\n",
    "        if 'lat' in ds.variables and 'lon' in ds.variables:\n",
    "            x,y = np.array(ds.variables['lon'][:]),np.array(ds.variables['lat'][:])\n",
    "        elif 'latitude' in ds.variables and 'longitude' in ds.variables:\n",
    "            x,y = np.array(ds.variables['longitude'][:]),np.array(ds.variables['latitude'][:])\n",
    "        else:\n",
    "            raise ValueError(\"Unable to find latitude and longitude variables in the dataset.\")\n",
    "        x = np.where(x<0,x+360,x)\n",
    "        var_field = np.array(ds.variables[var][:])\n",
    "    return var_field,x,y,dt\n",
    "\n",
    "\n",
    "def concatenate_wind(root1,var1,root2,var2,year0,yearn,month):\n",
    "    years = np.arange(year0,yearn,1)\n",
    "    for count,year in enumerate(years):\n",
    "        #Returns the gcm file that contains the year.\n",
    "        file = find_gcm_file(root1,year,month)\n",
    "        temp1,x,y,temp_dt = extract_gcm_data(file,var1,year,month)\n",
    "        \n",
    "        file = find_gcm_file(root2,year,month)\n",
    "        temp2,x,y,temp_dt = extract_gcm_data(file,var2,year,month)\n",
    "        \n",
    "        temp = ((temp1**2) + (temp2**2))**0.5\n",
    "        temp = np.nanpercentile(temp, 90,axis= 0)\n",
    "        temp = temp[np.newaxis,:]\n",
    "        \n",
    "        if count == 0:\n",
    "            series = temp\n",
    "            dt = temp_dt\n",
    "        else:\n",
    "            series = np.vstack((series,temp))\n",
    "            dt = np.append(dt,temp_dt)\n",
    "    return series,dt,x,y\n",
    "\n",
    "def find_gcm_file(root_directory,year,month):\n",
    "    for root, dirs, files in os.walk(root_directory):\n",
    "        filecheck = False\n",
    "        for file in files:\n",
    "            filecheck = yearcheck(os.path.join(root, file),year,month)\n",
    "            if filecheck == False:\n",
    "                continue\n",
    "            else:\n",
    "                matching_file = (os.path.join(root, file))\n",
    "                break\n",
    "        if filecheck == False:\n",
    "            matching_file = []\n",
    "            print(f'A file which contained the year {year} was not found!')\n",
    "    return matching_file\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a43e21-7621-4352-8c88-e4704622eb77",
   "metadata": {},
   "source": [
    "### Define the function to take regional averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0de601ca-f41d-403d-be59-b8f4d007fa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sea_aves(field,seas,x,y):\n",
    "    sea_names = []\n",
    "    if np.nanmax(x)>180:\n",
    "        x = np.where(x>180,x-360,x)\n",
    "    xv, yv = np.meshgrid(x, y)\n",
    "    for index, row in seas.iterrows():\n",
    "        name = row['name']\n",
    "        sea_names.append(name)\n",
    "        poly = row['geometry']\n",
    "        nodes= np.where(shapely.vectorized.contains(poly, xv, yv))\n",
    "        sea_nodes = field[:,nodes[0],nodes[1]]\n",
    "        if index == 0:\n",
    "            sea_sum = np.nanmean(sea_nodes,axis = 1)\n",
    "        else:\n",
    "            temp = np.nanmean(sea_nodes,axis =1)\n",
    "            sea_sum = np.vstack((sea_sum,temp)) \n",
    "    return sea_sum,sea_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b630f3d6-6841-417b-a0dc-1b1e92fd40e6",
   "metadata": {},
   "source": [
    "# Derive the timeseries interating over models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db01ec7-de0b-4a67-ad65-fce1d54ea581",
   "metadata": {},
   "outputs": [],
   "source": [
    "months = [7,9,11]\n",
    "year0 = 2020\n",
    "yearn = 2070\n",
    "\n",
    "fn = 'Regions.shp'\n",
    "seas = gpd.GeoDataFrame.from_file(fn)\n",
    "\n",
    "#loop ove the climate models' data\n",
    "for model_name in ['CNRM','ECEARTH','MPI','MRI']\n",
    "\n",
    "    root1 = f'WIND_ANALYSIS/{model_name}/uas'\n",
    "    root2 = f'WIND_ANALYSIS/{model_name}/vas'\n",
    "\n",
    "    for i,month in enumerate(months):\n",
    "        u10,dt,x,y = concatenate_wind(root1,'uas',root2,'vas',year0,yearn,month)\n",
    "        u10_temp,regions = sea_aves(u10,seas,x,y)\n",
    "        if i == 0:\n",
    "            seas_u10 = u10_temp\n",
    "        else:\n",
    "            seas_u10 = np.vstack((seas_u10,u10_temp))\n",
    "    \n",
    "    months = ['July','September','November']\n",
    "    cols = [x+str(' ')+y for (x,y) in product(months,regions)]\n",
    "\n",
    "    df = pd.DataFrame(seas_u10.T, columns=cols)\n",
    "    years = np.arange(year0,yearn,1)\n",
    "    df.insert(0, ('year', ''), years)\n",
    "    df.to_csv(f'{model_name}_u10_90_series.csv', index=False)\n",
    "    print(f\"{model_name}_u10_90_series.csv file saved successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-geo_environment]",
   "language": "python",
   "name": "conda-env-.conda-geo_environment-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
