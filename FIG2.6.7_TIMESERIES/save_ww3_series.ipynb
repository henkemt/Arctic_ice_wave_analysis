{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d27269f-3364-4b62-8d90-2a2ccd02bc2d",
   "metadata": {},
   "source": [
    "# Preprocess WW3 Series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1d1380a-624b-4d91-b6ff-0782ca847869",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import os\n",
    "import geopandas as gpd\n",
    "import shapely.vectorized\n",
    "import pandas as pd\n",
    "from itertools import product\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88447f7c-accd-43bc-9b65-58eaf22fc4bf",
   "metadata": {},
   "source": [
    "### Function to find, read, and concatenate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "010063f9-7122-49e5-b575-c3eca9c8c16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ww3_file(root_directory,year):\n",
    "    for root, dirs, files in os.walk(root_directory):\n",
    "        for file in files:\n",
    "            if str(year) in file:\n",
    "                matching_file = (os.path.join(root, file))\n",
    "    return matching_file\n",
    "\n",
    "def extract_ww3_data(ncfile,var,year,month):\n",
    "    with xr.open_dataset(ncfile) as ds:\n",
    "        ds = ds.sel(time=ds.time.dt.month.isin([month]))\n",
    "        dt = np.array(ds.coords['time'][:])        \n",
    "        x,y = np.array(ds.variables['longitude'][:]),np.array(ds.variables['latitude'][:])\n",
    "        var_field = np.array(ds.variables[var][:])\n",
    "    return var_field,x,y,dt\n",
    "\n",
    "def concatenate_ww3(rootdir,var,year0,yearn,month):\n",
    "    if var == 'hs':\n",
    "        rootvardir = rootdir + var\n",
    "    elif var == 'tp':\n",
    "        rootvardir = rootdir + var\n",
    "    \n",
    "    years = np.arange(year0,yearn,1)\n",
    "    \n",
    "    for count,year in enumerate(years):\n",
    "        file = find_ww3_file(rootvardir,year)\n",
    "\n",
    "        temp,x,y,temp_dt = extract_ww3_data(file,var,year,month)\n",
    "\n",
    "        if count == 0:\n",
    "            series = temp\n",
    "            dt = temp_dt\n",
    "        else:\n",
    "            series = np.vstack((series,temp))\n",
    "            dt = np.append(dt,temp_dt)\n",
    "    series = np.where(np.isnan(series),0,series)\n",
    "    return series,dt\n",
    "\n",
    "def wavefield_stats(hs,percentile):\n",
    "    hs_med = np.nanmedian(hs,axis =0)\n",
    "    hs_per = np.percentile(hs, percentile,axis = 0) \n",
    "    return hs_med, hs_per\n",
    "\n",
    "def wavefield_stats_3d(hs,percentile,year0,yearn):\n",
    "    years = np.arange(year0,yearn,1)\n",
    "    tsteps = hs.shape[0]//len(years)\n",
    "    for count,year in enumerate(years):\n",
    "        month_arr =hs[(count*tsteps):((count+1)*tsteps),:]\n",
    "        temp_med = np.nanmedian(month_arr,axis =0)\n",
    "        temp_per = np.percentile(month_arr, percentile,axis = 0) \n",
    "        if count == 0:\n",
    "            hs_med = temp_med\n",
    "            hs_per = temp_per\n",
    "        else:\n",
    "            hs_med = np.vstack((hs_med,temp_med))\n",
    "            hs_per = np.vstack((hs_per,temp_per))\n",
    "    return hs_med,hs_per"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a75c60-7b91-4921-b740-275c19bdb60d",
   "metadata": {},
   "source": [
    "### Load the depth file and mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "053b5d17-dc72-4838-95aa-d09a0063b8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "depthdir = 'ww3.2020_dpt.nc'\n",
    "with xr.open_dataset(depthdir) as ds:\n",
    "    depth = np.array(ds.variables['dpt'][0,:])\n",
    "    x,y = np.array(ds.variables['longitude'][:]),np.array(ds.variables['latitude'][:])\n",
    "    tris = np.array(ds.variables['tri'][:])\n",
    "    \n",
    "def depth_mask(depth,hs):\n",
    "    depth_ids = np.where(depth<15)\n",
    "    hs[:,depth_ids] = np.nan\n",
    "    return hs\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e87a1d0-658e-4675-8593-70cb272b3282",
   "metadata": {},
   "source": [
    "### Define the function to take regional averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a59331e-42a0-421f-9625-e25f1c971868",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sea_aves(hs,seas,x,y):\n",
    "    sea_names = []\n",
    "    for index, row in seas.iterrows():\n",
    "        name = row['name']\n",
    "        sea_names.append(name)\n",
    "        poly = row['geometry']\n",
    "        nodes= np.where(shapely.vectorized.contains(poly, x, y))[0]\n",
    "        sea_hs = hs[:,nodes]\n",
    "        if index == 0:\n",
    "            sea_ave_hs = np.nanmedian(sea_hs,axis = 1)\n",
    "        else:\n",
    "            temp = np.nanmedian(sea_hs,axis =1)\n",
    "            sea_ave_hs = np.vstack((sea_ave_hs,temp)) \n",
    "    return sea_ave_hs,sea_names\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1e5394-e655-4085-98e5-4b44f8854f82",
   "metadata": {},
   "source": [
    "# Derive the timeseries interating over models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80ccb15a-64c7-4ab0-8d44-9b1762a7228c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved successfully.\n"
     ]
    }
   ],
   "source": [
    "months = [7,9,11]\n",
    "year0 = 2020\n",
    "yearn = 2070\n",
    "\n",
    "for model_name in ['CNRM','ECEARTH','MPI','MRI']:\n",
    "    for i,month in enumerate(months):\n",
    "        \n",
    "        #Read the WW3 data\n",
    "        rootdir = f'/WW3/{model_name}/'\n",
    "        hs,dt = concatenate_ww3(rootdir,'hs',year0,yearn,month)\n",
    "        hs_med,hs_per = wavefield_stats_3d(hs,90,year0,yearn)\n",
    "        hs_med,hs_per = depth_mask(depth,hs_med),depth_mask(depth,hs_per)\n",
    "        \n",
    "        #Iterate over the months deriving monthly regional mean\n",
    "        fn = 'Regions.shp'\n",
    "        seas = gpd.GeoDataFrame.from_file(fn)\n",
    "        seas_temp,regions = sea_aves(hs_per,seas,x,y)\n",
    "        if i == 0:\n",
    "            seas_per = seas_temp\n",
    "        else:\n",
    "            seas_per = np.vstack((seas_per,seas_temp))\n",
    "    \n",
    "    #Create monthly regional column names\n",
    "    months = ['July','September','November']\n",
    "    cols = [x+str(' ')+y for (x,y) in product(months,regions)]\n",
    "\n",
    "    #Create the pandas dataframe and save it.\n",
    "    df = pd.DataFrame(seas_per.T, columns=cols)\n",
    "    years = np.arange(year0,yearn,1)\n",
    "    df.insert(0, ('year', ''), years)\n",
    "    df.to_csv(f'{model_name}_Hs90_series.csv', index=False)\n",
    "    print(f'{model_name}_Hs90_series.csv file saved successfully.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-geo_environment]",
   "language": "python",
   "name": "conda-env-.conda-geo_environment-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
