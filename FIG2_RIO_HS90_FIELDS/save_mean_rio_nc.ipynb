{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc9f757f-9911-4740-90f4-9c3a62dd8157",
   "metadata": {},
   "source": [
    "# Preprocessing RIO Fields\n",
    "This script outputs ensemble and time averaged RIO fields for a specific month.\n",
    "\n",
    "The process is run in for loop below iterating over momths jul, sep, nov and time slices 2020-2040, 2050-2070"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b80c7935-0742-4513-b527-65deeb497b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import pandas as pd\n",
    "from scipy import interpolate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71924a6-0c85-4e14-9fa1-05697a148757",
   "metadata": {},
   "source": [
    "### Functions for reading GCM data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8efe44e7-c0b0-4134-96c5-629020405c3c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def yearcheck(file, year):\n",
    "    check = True\n",
    "    with xr.open_dataset(file) as ds:\n",
    "        time = ds.coords['time'].values[:]\n",
    "        \n",
    "        if type(time[0]) == np.datetime64:\n",
    "            time = pd.to_datetime(time) \n",
    "            \n",
    "        ds_years= [time[i].year for i in range(len(time))]\n",
    "    if year not in ds_years:\n",
    "        check = False\n",
    "    return check\n",
    "\n",
    "def extract_gcm_data(ncfile,var,year,month):\n",
    "    with xr.open_dataset(ncfile) as ds:\n",
    "        ds = ds.where(((ds['time.year'] == year)), drop=True)\n",
    "        ds = ds.sel(time=ds.time.dt.month.isin([month]))\n",
    "        dt = np.array(ds.coords['time'][:])\n",
    "        if 'lat' in ds.variables and 'lon' in ds.variables:\n",
    "            x,y = np.array(ds.variables['lon'][:]),np.array(ds.variables['lat'][:])\n",
    "        elif 'latitude' in ds.variables and 'longitude' in ds.variables:\n",
    "            x,y = np.array(ds.variables['longitude'][:]),np.array(ds.variables['latitude'][:])\n",
    "        else:\n",
    "            raise ValueError(\"Unable to find latitude and longitude variables in the dataset.\")\n",
    "        x = np.where(x<0,x+360,x)\n",
    "        var_field = np.array(ds.variables[var][:])\n",
    "    return var_field,x,y,dt\n",
    "\n",
    "def gcm_interp(x,y,z,xgrid,ygrid):\n",
    "    x = np.ravel(x)\n",
    "    y = np.ravel(y)\n",
    "    if np.ndim(z) == 3:\n",
    "        for tstep in range(z.shape[0]):\n",
    "            ztemp = np.ravel(z[tstep,:,:])\n",
    "            temp = scipy.interpolate.griddata((x,y),ztemp,(xgrid,ygrid),method='nearest')\n",
    "            if tstep == 0:\n",
    "                zgrid = temp\n",
    "            else:\n",
    "                zgrid = np.dstack((zgrid,temp))\n",
    "        zgrid = np.transpose(zgrid, (2, 0, 1))\n",
    "    else:\n",
    "        ztemp = np.ravel(z[:,:])\n",
    "        temp = scipy.interpolate.griddata((x,y),ztemp,(xgrid,ygrid),method='linear')\n",
    "        temp1 = scipy.interpolate.griddata((x,y),ztemp,(xgrid,ygrid),method='nearest')\n",
    "        temp  = np.where(np.isnan(temp),temp1,temp)\n",
    "        zgrid = temp\n",
    "    return zgrid\n",
    "\n",
    "def concatenate_gcm(rootdir,var,year0,yearn,month):\n",
    "    years = np.arange(year0,yearn,1)\n",
    "    for count,year in enumerate(years):\n",
    "        file = find_gcm_file(rootdir,year)\n",
    "        temp,x,y,temp_dt = extract_gcm_data(file,var,year,month)\n",
    "        if count == 0:\n",
    "            series = temp\n",
    "            dt = temp_dt\n",
    "        else:\n",
    "            series = np.vstack((series,temp))\n",
    "            dt = np.append(dt,temp_dt)\n",
    "    return series,dt,x,y\n",
    "\n",
    "def find_gcm_file(root_directory,year):\n",
    "    for root, dirs, files in os.walk(root_directory):\n",
    "        filecheck = False\n",
    "        for file in files:\n",
    "            filecheck = yearcheck(os.path.join(root, file),year)\n",
    "            if filecheck == False:\n",
    "                continue\n",
    "            else:\n",
    "                matching_file = (os.path.join(root, file))\n",
    "                break\n",
    "        if filecheck == False:\n",
    "            matching_file = []\n",
    "            print(f'A file which contained the year {year} was not found!')\n",
    "    return matching_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86f1134-c764-476a-9144-afa509188afe",
   "metadata": {},
   "source": [
    "### Function to derive RIO fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c318fd7-2dfb-425d-849c-ff63012e56d4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def create_rio(sit,sic,ice_class):\n",
    "    sithick = sit\n",
    "    sithick = np.where(np.isnan(sithick),0,sithick)\n",
    "    siconc = sic\n",
    "    if np.nanmax(siconc) > 15:\n",
    "        siconc = siconc *0.01\n",
    "\n",
    "    sit_temp = np.array(sithick)\n",
    "    #Max SIT value in POLARIS is 3m\n",
    "    sit_temp = np.where(sit_temp>3,3.1,sit_temp)\n",
    "    for count, class_val in enumerate(ice_class):\n",
    "        bin_vals = np.where((sithick>min_sit[count])&(sithick<max_sit[count]))\n",
    "        sit_temp[bin_vals] = class_val\n",
    "\n",
    "    rio_ice = sit_temp*np.round(siconc, decimals=1)*10\n",
    "    rio_ow = (1-np.round(siconc, decimals=1))*30\n",
    "    rio = rio_ice+rio_ow\n",
    "    return rio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb733c9-51d6-4632-ac28-3cdadc55d6a0",
   "metadata": {},
   "source": [
    "### Load the polar classes' risk value csv file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac3189dc-ad13-43c2-89e8-a8ec94b1cde6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The selected vessel ice class is: NOICECLASS\n"
     ]
    }
   ],
   "source": [
    "csv_file = 'POLAR_CLASSES.csv'\n",
    "\n",
    "df = pd.read_csv(csv_file)\n",
    "min_sit = np.array(df.iloc[0, 2:])/100\n",
    "max_sit = np.array(df.iloc[1, 2:])/100\n",
    "ice_class = np.array(df.iloc[13, 2:])\n",
    "ice_class_name = np.array(df.iloc[13, 0])\n",
    "print(f'The selected vessel ice class is: {ice_class_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4ec16d-b35c-441e-82aa-4166c01f4f88",
   "metadata": {},
   "source": [
    "### Derive and save ensemble and yearly averages monthly RIO fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c480f7-9d8a-47f1-9d8c-959d358e7832",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "months = [7,9,11]\n",
    "year0s = [2020,2050]\n",
    "yearns = [2040,2070]\n",
    "\n",
    "for year0,yearn in zip(year0s,yearns):\n",
    "    for month in months:\n",
    "        output_filename = f'AVE_RIO_{year0}-{yearn}_{month}.nc'\n",
    "\n",
    "        rootdir = '/Sea Ice/CNRM/siconc'\n",
    "        sic,dt,x_cnrm,y_cnrm = concatenate_gcm(rootdir,'siconc',year0,yearn,month)\n",
    "        #Save a single timestep from the CNRM grid to later reapply masking nan values. \n",
    "        nan_mask = sic[0,:,:]\n",
    "        rootdir = '/Sea Ice/CNRM/sithick'\n",
    "        sit,dt,x_cnrm,y_cnrm = concatenate_gcm(rootdir,'sithick',year0,yearn,month)\n",
    "        cnrm_rio = create_rio(sit,sic,ice_class)\n",
    "        cnrm_rio = np.nanmean(cnrm_rio,axis =0)\n",
    "\n",
    "        #ECEARTH\n",
    "        rootdir = 'Sea Ice/ECEARTH/siconc'\n",
    "        sic,dt,x_temp,y_temp = concatenate_gcm(rootdir,'siconc',year0,yearn,month)\n",
    "        rootdir = 'Sea Ice/ECEARTH/sithick'\n",
    "        sit,dt,x_temp,y_temp = concatenate_gcm(rootdir,'sithick',year0,yearn,month)\n",
    "        temp_rio = create_rio(sit,sic,ice_class)\n",
    "        temp_rio = np.nanmean(temp_rio,axis =0)\n",
    "        ecearth_rio = gcm_interp(x_temp,y_temp,temp_rio,x_cnrm,y_cnrm)\n",
    "\n",
    "        #MPI\n",
    "        rootdir = '/Sea Ice/MPI/siconc'\n",
    "        sic,dt,x_temp,y_temp = concatenate_gcm(rootdir,'siconc',year0,yearn,month)\n",
    "        rootdir = '/Sea Ice/MPI/sithick'\n",
    "        sit,dt,x_temp,y_temp = concatenate_gcm(rootdir,'sithick',year0,yearn,month)\n",
    "        temp_rio = create_rio(sit,sic,ice_class)\n",
    "        temp_rio = np.nanmean(temp_rio,axis =0)\n",
    "        mpi_rio = gcm_interp(x_temp,y_temp,temp_rio,x_cnrm,y_cnrm)\n",
    "\n",
    "\n",
    "        #MRI\n",
    "        rootdir = '/Sea Ice/MRI/siconc'\n",
    "        sic,dt,x_temp,y_temp = concatenate_gcm(rootdir,'siconc',year0,yearn,month)\n",
    "        rootdir = '/Sea Ice/MRI/sithick'\n",
    "        sit,dt,x_temp,y_temp = concatenate_gcm(rootdir,'sithick',year0,yearn,month)\n",
    "        temp_rio = create_rio(sit,sic,ice_class)\n",
    "        temp_rio = np.nanmean(temp_rio,axis =0)\n",
    "        mri_rio = gcm_interp(x_temp,y_temp,temp_rio,x_cnrm,y_cnrm)\n",
    "\n",
    "        ave_rio = np.array([cnrm_rio,ecearth_rio,mri_rio,mpi_rio])\n",
    "        ave_rio = np.nanmean(ave_rio,axis =0)\n",
    "        ave_rio = np.where(np.isnan(nan_mask),np.nan,ave_rio)\n",
    "\n",
    "        #Save the CNRM for plotting\n",
    "        x = x_cnrm.shape[0]\n",
    "        y = x_cnrm.shape[1]\n",
    "\n",
    "        ice_data_array = xr.DataArray(ave_rio,\n",
    "                                      dims=('x', 'y'),\n",
    "                                      coords={'x': np.arange(x),\n",
    "                                              'y': np.arange(y)},\n",
    "                                      name='RIO')\n",
    "\n",
    "        lat_array = xr.DataArray(y_cnrm,\n",
    "                                 dims=('x', 'y'),\n",
    "                                 coords={'x': np.arange(x),\n",
    "                                         'y': np.arange(y)},\n",
    "                                 name='lat')\n",
    "\n",
    "        lon_array = xr.DataArray(x_cnrm,\n",
    "                                 dims=('x', 'y'),\n",
    "                                 coords={'x': np.arange(x),\n",
    "                                         'y': np.arange(y)},\n",
    "                                 name='lon')\n",
    "\n",
    "        dataset = xr.Dataset({'RIO': ice_data_array, 'lat': lat_array, 'lon': lon_array})\n",
    "        dataset.to_netcdf(output_filename)\n",
    "        print(f\"NetCDF file '{output_filename}' saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:geo_env39]",
   "language": "python",
   "name": "conda-env-geo_env39-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
